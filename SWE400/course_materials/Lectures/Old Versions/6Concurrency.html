<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head><meta content="text/html; charset=ISO-8859-1" http-equiv="content-type"><title>Concurrency</title></head><body><h1>Concurrency</h1>Now things get complicated<br><br><h2>Concurrency Problems</h2>Correctness<br><ul><li>Lost Updates - A overwrites B&#8217;s changes because A read first and B wrote first</li><li>Inconsistent Read - 2 things that are correct, but not at the same time<br></li></ul>Liveness<br><ul><li>How much concurrency can happen</li></ul><h2>Execution Contexts</h2><ul><li>Request - a single call into the system</li><ul><li>Largely the server&#8217;s responsibility and usually can&#8217;t be interrupted by user</li></ul><li>Session - long running interaction between client and a server</li><ul><li>A logical sequence of requests</li></ul><li>Process - heavyweight execution process</li><ul><li>Internal data is isolated</li></ul><li>Thread - lightweight execution process within a process</li><ul><li>Shared memory -&gt; concurrency problems</li></ul><ul><li>Isolated threads don&#8217;t share memory</li></ul></ul><br>Would like each session to be a process<br><ul><li>That isn&#8217;t generally available</li><li>Would take a lot of resources to create them and throw them away<br></li></ul>Transaction context<br><ul><li>System transaction - application to DB</li><li>Business transaction - user to application</li></ul><h2>Strategies to Reduce Concurrency</h2><ul><li>Isolation - partition the data so only one &#8220;active agent&#8221; has access to it.</li><ul><li>&#8220;Arrange things so that the program enters an isolation zone within which you don&#8217;t have to worry about concurrency.&#8221;</li><li>Good concurrency design = &#8220;Making such zones and ensuring that as much of the programming as possible is done in one of them&#8221;</li><li>What does that really mean?<br></li></ul></ul><ul><li>Immutability - data that can&#8217;t change doesn&#8217;t have concurrency issues</li></ul><h2>Optimistic vs Pessimistic Concurrency Control</h2>Optimistic: Detect conflicts<br>Pessimistic: Prevent conflicts<br><br>If conflicts are rare and easy to detect =&gt; optimistic<br>If conflicts are common +&gt; pessimistic<h3>Optimistic Locking </h3><ul><li>Give multiple agents edit rights to the data</li><li>First to finish can save without worry</li><li>When rest save, have to make sure earlier writes aren&#8217;t lost</li><li>What if two wrote different values to the same thing?</li><li>Locks only held on writes,&nbsp; but saves are more complex</li></ul><h3>Pessimistic Locking</h3><ul><li>First to access locks the resource preventing access until finished</li><li>Reduces concurrency</li></ul><h2>Preventing Inconsistent Reads</h2>Only happens if we have to read multiple pieces in separate actionsHow do we ensure they all are consistent?<br><ul><li>Pessimistic</li><ul><li>Read locks - shared</li></ul><ul><li>Write locks - </li></ul><ul><ul><li>Only one and can&#8217;t lock it if anyone has the read lock</li></ul></ul><ul><ul><li>Once it is locked, no one can get any locks</li></ul></ul><li>Optimistic</li><ul><li>Conflict detection depends on a version marker (timestamp or sequential counter)</li></ul><ul><li>Lost update prevention - version you are writing should match the existing and the gets updated on write</li></ul><ul><li>Inconsistent read - versions of each piece must match - Really???</li></ul></ul><h4>Temporal Reads</h4><ul><li>Data gets timestamp or version number</li><li>DB returns data as it was at that time</li><li>DB is a full temporal history</li></ul><h3>Deadlocks</h3><ul><li>Locks in a DB can cause deadlock just like locks in OS</li><li>Can only deadlock if all of these:</li><ul><li>Mutual exclusion</li><li>Hold and wait</li><li>No preemption</li><li>Circular wait</li></ul></ul><h4>Deadlock Recovery</h4><ul><li>Victim</li><ul><li>After detection</li></ul><ul><li>Pick one agent who has to throw everything away (rollback) and start over</li></ul><li>Lock Time Limit</li><ul><li>If anyone holds a lock for too long, they have to throw everything away and start oveer</li></ul><ul><li>Similar to victim,&nbsp; but doesn&#8217;t require detection</li></ul></ul><h4>Deadlock Prevention</h4><ul><li>Get all of the locks at the beginning of work</li><ul><li>Does that really prevent anything?</li></ul><ul><li>Just makes it so you don&#8217;t have to rollback when you get victimized</li></ul><li>Order the locks</li><li>Only one agent can hold locks at one time</li><ul><li>How does that affect concurrency/liveness?</li></ul></ul><h2>Transactions</h2><ul><li>Bounded sequence of work</li><li>Well-defined start and end points</li><li>Resources are consistent at start and end</li><li>Undividable </li><li>(could be system or DB)</li></ul><br><h3>ACID Characteristics</h3>Required for all transactions - ensures no concurrency problems<br><ul><li>Atomicity - all or nothing</li><li>Consistency - at beginning and at end</li><li>Isolation - not visible to other resources until complete</li><li>Durability - committed effect must be permanent</li></ul><h3>Transaction Resources</h3><ul><li>Length of a transaction is inversely proportional to the effect on throughput</li><ul><li>Want them to be short</li></ul><li>&#8220;Long transaction&#8221; - spans multiple requests - makes it hard to achieve ACID characteristics and maintain liveness</li><li>&#8220;Late transaction&#8221; - reads are outside the transactions </li><ul><li>Only updates are inside the transaction</li></ul><ul><li>Leaves the door open for inconsistent reads (really?)</li></ul><ul><li>Leaves the door open for lost updates (really?)</li></ul></ul><h2>Lock Escalation</h2>If we lock too many rows in a table<br><ul><li>DB may force us to lock the table</li><li>What would cause this?</li><li>Imagine having a table for a Domain SuperType pattern . . .</li></ul></body></html>